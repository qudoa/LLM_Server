"""ç”¨äº NCU profiling çš„ append_paged_kv_cache æµ‹è¯•è„šæœ¬"""
import torch
import flashinfer
import torch.cuda.profiler as profiler

# --- é…ç½®å‚æ•° ---
num_kv_heads = 4        # KV å¤´æ•°ï¼ˆGQA: æ¯ä¸ª KV å¤´å¯ä»¥æœåŠ¡å¤šä¸ª Q å¤´ï¼‰
head_dim = 128          # æ¯ä¸ªå¤´çš„ç»´åº¦
page_size = 16          # æ¯é¡µå­˜å‚¨çš„ token æ•°ï¼ˆç±»ä¼¼ OS çš„é¡µå¤§å°ï¼‰
device = "cuda:0"
dtype = torch.float16

# --- åœºæ™¯è®¾ç½®: å·²æœ‰ 4096 ä¸ª tokenï¼Œè¿½åŠ ç¬¬ 4097 ä¸ª ---
current_seq_len = 4096  # å½“å‰å·²ç¼“å­˜çš„åºåˆ—é•¿åº¦
nnz_kv = 256              # è¦è¿½åŠ çš„ token æ•°é‡ï¼ˆé€šå¸¸æ˜¯ 1ï¼‰ã€å¯æ”¹: 1, 16, 32, 64, 128, 256ã€‘

# è®¡ç®—éœ€è¦çš„æ€»é¡µæ•°
# 4096 ä¸ª token éœ€è¦ 256 é¡µï¼ˆæ¯é¡µ 16 ä¸ªï¼‰ï¼Œè¿½åŠ  1 ä¸ªåéœ€è¦ 257 é¡µ
total_seq_len = current_seq_len + nnz_kv
num_pages_needed = (total_seq_len + page_size - 1) // page_size  # å‘ä¸Šå–æ•´

# --- åˆ›å»º Page Poolï¼ˆå…¨å±€é¡µæ± ï¼Œç±»ä¼¼ç‰©ç†å†…å­˜ï¼‰---
max_num_pages = 60000   # é¡µæ± æ€»å®¹é‡ï¼ˆæ‰€æœ‰è¯·æ±‚å…±äº«ï¼‰
paged_kv_cache = torch.empty(
    max_num_pages,      # é¡µæ± å¤§å°
    2,                  # K å’Œ Vï¼ˆç»´åº¦ 0: K, ç»´åº¦ 1: Vï¼‰
    page_size,          # æ¯é¡µçš„ token å®¹é‡
    num_kv_heads,       # KV å¤´æ•°
    head_dim,           # æ¯ä¸ªå¤´çš„ç»´åº¦
    device=device, dtype=dtype
)

# éšæœºåˆ†é…é¡µï¼ˆæ¨¡æ‹Ÿå†…å­˜ç¢ç‰‡åŒ–ï¼Œå®é™…æ¨ç†ä¸­é¡µåˆ†å¸ƒä¸è¿ç»­ï¼‰
all_indices = torch.randperm(max_num_pages, device=device, dtype=torch.int32)
kv_page_indices = all_indices[:num_pages_needed]  # ä¸ºè¿™ä¸ªè¯·æ±‚åˆ†é… 257 ä¸ªä¸è¿ç»­çš„é¡µ

# --- æ„é€ é¡µè¡¨å…ƒæ•°æ®ï¼ˆç±»ä¼¼è¿›ç¨‹çš„é¡µè¡¨ï¼‰---
# kv_page_indptr: æ ‡è®°æ¯ä¸ªè¯·æ±‚ä½¿ç”¨çš„é¡µç´¢å¼•èŒƒå›´
# [0, 257] è¡¨ç¤ºè¯·æ±‚ 0 ä½¿ç”¨ kv_page_indices[0:257]
kv_page_indptr = torch.tensor([0, num_pages_needed], dtype=torch.int32, device=device)

# kv_last_page_len: æœ€åä¸€é¡µå½“å‰çš„å¡«å……é•¿åº¦
# 0 è¡¨ç¤ºæœ€åä¸€é¡µï¼ˆPage 255ï¼‰å·²æ»¡ï¼Œæ–° token ä¼šåœ¨æ–°é¡µï¼ˆPage 256ï¼‰çš„ä½ç½® 0
kv_last_page_len = torch.tensor([0], dtype=torch.int32, device=device)

# --- æ„é€ è¦è¿½åŠ çš„ K/V æ•°æ® ---
k_append = torch.randn(nnz_kv, num_kv_heads, head_dim, device=device, dtype=dtype)
v_append = torch.randn(nnz_kv, num_kv_heads, head_dim, device=device, dtype=dtype)

# --- ç”Ÿæˆå†™å…¥ä½ç½®ä¿¡æ¯ ---
# kv_append_indptr: æ ‡è®°æ¯ä¸ªè¯·æ±‚è¦è¿½åŠ å¤šå°‘ä¸ª tokenï¼ˆè¿™é‡Œåªæœ‰ 1 ä¸ªè¯·æ±‚ï¼‰
kv_append_indptr = torch.tensor([0, nnz_kv], dtype=torch.int32, device=device)

# seq_lens: è®¡ç®—å½“å‰åºåˆ—çš„å®é™…é•¿åº¦ï¼ˆåŸºäºé¡µè¡¨å’Œ last_page_lenï¼‰
seq_lens = flashinfer.get_seq_lens(kv_page_indptr, kv_last_page_len, page_size)

# batch_indices: æ¯ä¸ª token å±äºå“ªä¸ªè¯·æ±‚ï¼ˆè¿™é‡Œéƒ½æ˜¯ 0ï¼‰
# positions: æ¯ä¸ª token åœ¨åºåˆ—ä¸­çš„ä½ç½®ï¼ˆè¿™é‡Œæ˜¯ 4095ï¼Œå› ä¸º 0-indexedï¼‰
batch_indices, positions = flashinfer.get_batch_indices_positions(
    kv_append_indptr, seq_lens, nnz_kv
)

# --- Warmupï¼ˆé¿å… JIT ç¼–è¯‘å½±å“ profiling ç»“æœï¼‰---
# åœæ­¢ profilingï¼ˆè·³è¿‡ warmupï¼‰
profiler.stop()
for _ in range(3):
    flashinfer.page.append_paged_kv_cache(
        k_append, v_append, batch_indices, positions,
        paged_kv_cache, kv_page_indices, kv_page_indptr, kv_last_page_len
    )
torch.cuda.synchronize()  # ç¡®ä¿ GPU æ“ä½œå®Œæˆ

print("ğŸ”¥ å¼€å§‹ profiling...")

# å¯åŠ¨ profilingï¼ˆåª profile åé¢ 3 æ¬¡ï¼‰
profiler.start()

# --- æ­£å¼ Profiling: è·‘ 3 æ¬¡å–å¹³å‡ ---
for i in range(3):
    # NVTX æ ‡è®°ï¼šåœ¨ ncu-ui ä¸­å¯ä»¥çœ‹åˆ°æ¯æ¬¡è°ƒç”¨
    torch.cuda.nvtx.range_push(f"append_paged_kv_cache_{i}")
    
    # æ ¸å¿ƒæ“ä½œï¼šæŠŠæ–° token çš„ K/V å†™å…¥åˆ°å¯¹åº”çš„é¡µä¸­
    # å†…éƒ¨ä¼šæ ¹æ® positions è®¡ç®—é¡µå·å’Œé¡µå†…åç§»ï¼Œæ‰§è¡Œå†™å…¥
    flashinfer.page.append_paged_kv_cache(
        k_append,           # [1, 4, 128] - è¦è¿½åŠ çš„ K
        v_append,           # [1, 4, 128] - è¦è¿½åŠ çš„ V
        batch_indices,      # [0] - å±äºè¯·æ±‚ 0
        positions,          # [4095] - å†™å…¥ä½ç½®ï¼ˆ0-indexedï¼‰
        paged_kv_cache,     # [60000, 2, 16, 4, 128] - å…¨å±€é¡µæ± 
        kv_page_indices,    # [257] - è¿™ä¸ªè¯·æ±‚çš„é¡µå·åˆ—è¡¨
        kv_page_indptr,     # [0, 257] - é¡µç´¢å¼•èŒƒå›´
        kv_last_page_len    # [0] - æœ€åä¸€é¡µé•¿åº¦
    )
    
    torch.cuda.nvtx.range_pop()

torch.cuda.synchronize()  # ç­‰å¾…æ‰€æœ‰ GPU æ“ä½œå®Œæˆ

# åœæ­¢ profiling
profiler.stop()
print("âœ… Profiling å®Œæˆ!")

# ============================================================
# NCU Profiling å‘½ä»¤ä½¿ç”¨æŒ‡å—
# ============================================================
#
# ä½¿ç”¨ cudaProfilerStart/Stop æ§åˆ¶ profiling èŒƒå›´ï¼ˆåª profile warmup åçš„ 3 æ¬¡è°ƒç”¨ï¼‰:
#
# 1. åŸºç¡€ profilingï¼ˆæ¨èï¼‰:
#    ncu --set full --kernel-name "AppendPagedKVCacheKernel" \
#        -o append_profile python append_paged_kvcache.py
#
# 2. æŸ¥çœ‹å†…å­˜ååé‡ï¼ˆå¿«é€ŸæŒ‡æ ‡ï¼‰:
#    ncu --metrics dram__throughput.avg.pct_of_peak_sustained_elapsed,sm__throughput.avg.pct_of_peak_sustained_elapsed \
#        --kernel-name "AppendPagedKVCacheKernel" \
#        python append_paged_kvcache.py
#
# 3. å¯¼å‡º CSV æ ¼å¼:
#    ncu --csv --metrics dram__throughput.avg.pct_of_peak_sustained_elapsed \
#        --kernel-name "AppendPagedKVCacheKernel" \
#        python append_paged_kvcache.py > append_metrics.csv
#
# 4. æŸ¥çœ‹ç»“æœï¼ˆéœ€è¦åœ¨ Windows æˆ–æœ‰ GUI çš„ç¯å¢ƒï¼‰:
#    ncu-ui append_profile.ncu-rep
#
# 5. å‘½ä»¤è¡ŒæŸ¥çœ‹ç»Ÿè®¡ï¼ˆæ— éœ€ GUIï¼‰:
#    ncu --print-summary per-kernel append_profile.ncu-rep
#
# ============================================================


# use this :
# ncu -f  --set full --kernel-name  "AppendPagedKVCacheKernel" -o append_profile python append_paged_kvcache.py